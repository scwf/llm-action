# 深度神经网络思维导图 (细化版 - 已优化)

## 一、基础构件 (Fundamental Building Blocks)

### 1. 神经元 (Neuron / Perceptron)
#### **基本模型**
模拟生物神经元，接收输入，进行加权求和，然后通过激活函数输出。

#### **权重 (Weights, $w$)**
##### **概念**
每个输入特征 $x_i$ 都分配有一个权重 $w_i$，表示该特征对神经元输出的贡献程度或重要性。权重可正可负，调整特征重要性。

##### **原理**
权重是模型的可学习参数，在训练过程中通过梯度下降等优化算法不断调整，以最小化损失函数。

##### **初始化**
权重的初始值对模型训练至关重要，不良的初始化可能导致梯度消失/爆炸或收敛缓慢。

#### **偏置 (Bias, $b$)**
##### **概念**
一个额外的可学习参数，独立于输入，为神经元的激活提供一个基础偏移量。允许激活函数的决策边界不必须通过原点，从而增加模型的灵活性，使其能够拟合非零截距的数据。

##### **原理**
偏置项可以看作是权重为1，输入恒为1的特殊权重。同样通过反向传播更新。

#### **线性组合 (Linear Combination)**
##### **公式**
$$z = w_1x_1 + w_2x_2 + ... + w_nx_n + b = w^\top x + b$$

##### **作用**
将输入特征进行加权汇总，得到一个净输入值 $z$，该值随后被送入激活函数。

### 2. 激活函数 (Activation Functions)
#### **目的**
引入非线性，使得神经网络能够学习和表示复杂的数据模式。如果没有非线性激活函数，多层神经网络本质上等同于一个单层线性模型。

#### **常见类型**
##### **Sigmoid**
###### **公式**
$$\sigma(x) = \frac{1}{1 + e^{-x}}$$

###### **概念**
S 形曲线，将任意实数输入映射到 (0, 1) 区间。输出可解释为概率（例如在二分类任务的输出层）。

###### **原理**
函数处处可导，其导数为 $$\sigma'(x) = \sigma(x)(1-\sigma(x))$$

###### **优点**
输出范围有限，可以用作概率表示；平滑可导。

###### **缺点**
**梯度消失 (Vanishing Gradient Problem)**: 当输入值绝对值较大时，函数梯度趋近于0，导致反向传播时梯度信号微弱，深层网络难以训练。

**输出非零中心**: 输出值恒大于0，可能导致后续层接收到的输入总是正的，影响收敛速度（"ZigZag"现象）。

**计算成本**: 指数运算相对耗时。

##### **Tanh (双曲正切)**
###### **公式**
$$\tanh(x) = \frac{e^x - e^{-x}}{e^x + e^{-x}} = 2\sigma(2x) - 1$$

###### **概念**
S 形曲线，将任意实数输入映射到 (-1, 1) 区间。

###### **原理**
导数为 $$1 - \tanh^2(x)$$

###### **优点**
输出以0为中心 (zero-centered)，相比 Sigmoid 通常收敛更快，因为下一层接收的输入有正有负，更符合期望。

###### **缺点**
仍然存在梯度饱和问题（输入绝对值大时梯度趋近0）。计算成本。

##### **ReLU (Rectified Linear Unit)**
###### **公式**
$$f(x) = \max(0, x)$$

###### **概念**
当输入为正时，输出等于输入；当输入为负时，输出为0。目前最常用的非线性激活函数之一。

###### **原理**
在正区间梯度恒为1，负区间梯度恒为0。

###### **优点**
**计算高效**: 只需比较和赋值操作。

**缓解梯度消失**: 在正区间梯度恒为1，不会饱和。

**稀疏性**: 使一部分神经元输出为0，网络更稀疏，减少参数依赖，可能缓解过拟合。

**收敛快**: 相比 Sigmoid/Tanh 通常收敛更快。

###### **缺点**
**神经元死亡 (Dying ReLU Problem)**: 如果一个神经元在所有训练样本上的输入都为负，那么它的梯度将永远为0，导致其权重无法更新。

**输出非零中心**: 与 Sigmoid 类似。

##### **Leaky ReLU / PReLU / ELU**
###### **Leaky ReLU**
**公式**: $$f(x) = \begin{cases} x & \text{if } x > 0 \\ \alpha x & \text{if } x \le 0 \end{cases}$$ 其中 $\alpha$ 是一个小的正常数 (如0.01)。

**概念**: 允许在负输入区间有一个小的、非零的梯度。

**原理**: 缓解 ReLU 死亡问题，保留稀疏激活的同时允许负梯度通过。

###### **PReLU (Parametric ReLU)**
**概念**: $\alpha$ 不是预设的超参数，而是模型学习到的参数。

###### **ELU (Exponential Linear Unit)**
**公式**: $$f(x) = \begin{cases} x & \text{if } x > 0 \\ \alpha(e^x - 1) & \text{if } x \le 0 \end{cases}$$ $\alpha > 0$。

**概念**: 负区间的输出是指数函数，具有饱和特性。

**优点**: 输出均值接近0，比 ReLU 更鲁棒，缓解 Dying ReLU。

**缺点**: 计算成本略高于 ReLU。

##### **GELU (Gaussian Error Linear Unit)**
###### **公式**
$x \cdot \Phi(x)$，其中 $\Phi(x)$ 是高斯正态分布的累积分布函数。近似为 $$ x \Phi(x) \approx 0.5x\left(1 + \tanh\left[\sqrt{\frac{2}{\pi}}(x + 0.044715x^3)\right]\right) $$

###### **概念**
BERT、GPT 等 Transformer 模型中常用的激活函数。被认为是 ReLU 的平滑近似。

###### **原理**
结合了输入的随机正则化思想，其激活值是输入乘以一个伯努利分布的期望（该伯努利分布的参数由输入决定）。用高斯累积分布函数来建模这种随机性，使得激活与输入值的大小平滑相关。

### 3. 权重初始化 (Weight Initialization)
#### **目的**
避免梯度消失或梯度爆炸，确保训练初期的信息有效传播，加速收敛。打破对称性（如果所有权重初始化为相同值，则同一层所有神经元将学习到相同特征）。

#### **常见方法**
##### **零初始化/常数初始化**
通常不推荐用于权重（会导致对称性问题），但偏置常初始化为0或小的正数。

##### **随机初始化 (小随机数)**
从均值为0，方差较小的高斯分布或均匀分布中采样。

##### **Xavier / Glorot 初始化**
###### **概念**
针对 Sigmoid 或 Tanh 等饱和型激活函数设计。目标是使前向传播时激活值的方差和反向传播时梯度的方差在层间保持一致。

###### **原理**
均匀分布: 采样于 $$\mathcal{U}\left(-\sqrt{\frac{6}{n_{\text{in}}+n_{\text{out}}}},\, \sqrt{\frac{6}{n_{\text{in}}+n_{\text{out}}}}\right)$$

正态分布: 采样于 $$\mathcal{N}\left(0,\, \text{Var}=\frac{2}{n_{\text{in}}+n_{\text{out}}}\right)$$

其中 $n_{\text{in}}$ 和 $n_{\text{out}}$ 分别是该层输入和输出神经元的数量。

##### **He / Kaiming 初始化**
###### **概念**
专门针对 ReLU 及其变体 (Leaky ReLU 等) 设计的初始化方法。

###### **原理**
考虑到 ReLU 会将负值置零，大约一半的神经元输出为0，因此调整方差以适应这种情况，保证正区间的期望梯度稳定。

均匀分布: 采样于 $$\mathcal{U}\left(-\sqrt{\frac{6}{n_{\text{in}}}},\, \sqrt{\frac{6}{n_{\text{in}}}}\right)$$

正态分布: 采样于 $$\mathcal{N}\left(0,\, \text{Var}=\frac{2}{n_{\text{in}}}\right)$$

## 二、训练与优化 (Training and Optimization)

### 1. 损失函数 (Loss Functions / Cost Functions / Objective Functions)
#### **目的**
量化模型预测值与真实目标值之间的差异。训练的目标是最小化损失函数。

#### **常见类型**
##### **MSE (Mean Squared Error / L2 Loss)**
###### **公式**
$$L(y, \hat{y}) = \frac{1}{N}\sum_{i=1}^{N} (y_i - \hat{y}_i)^2$$

###### **概念**
预测值与真实值之差的平方的均值。回归任务中最常用。

###### **原理**
对误差进行平方，因此对较大的误差给予更大的惩罚。梯度大小与误差成正比。

###### **特点**
对异常值敏感。

##### **MAE (Mean Absolute Error / L1 Loss)**
###### **公式**
$$L(y, \hat{y}) = \frac{1}{N}\sum_{i=1}^{N} |y_i - \hat{y}_i|$$

###### **概念**
预测值与真实值之差的绝对值的均值。

###### **特点**
相对于 MSE，对异常值更鲁棒。梯度在0点不可导 (实际应用中可采用次梯度)。

##### **交叉熵损失 (Cross-Entropy Loss)**
###### **概念**
衡量两个概率分布 (模型预测分布与真实标签分布) 之间的差异。分类任务首选。

###### **原理**
**二元交叉熵 (Binary Cross-Entropy, BCE)**: 用于二分类问题。
$$L(y, \hat{y}) = -[y \log(\hat{y}) + (1-y) \log(1-\hat{y})]$$
(通常与 Sigmoid 输出层结合)

**分类交叉熵 (Categorical Cross-Entropy)**: 用于多分类问题。
$$L(y, \hat{y}) = -\sum_{c=1}^{C} y_c \log(\hat{y}_c)$$
(其中 $y$ 是 one-hot 编码的真实标签，$\hat{y}$ 是 Softmax 输出的概率分布，C是类别数。与 Softmax 激活函数联用时，梯度计算简洁高效。)

##### **Hinge 损失 (Hinge Loss)**
###### **公式**
$$L(y, \hat{y}) = \max(0, 1 - y \cdot \hat{y})$$ (其中 $y$ 通常取值为 $\{-1, 1\}$，$\hat{y}$ 是分类器的原始输出，非概率)

###### **概念**
源于支持向量机 (SVM) 的最大间隔分类思想。

###### **原理**
目标是使正确分类的样本与决策边界的间隔至少为1。对于分类正确且间隔足够的样本 ($y \cdot \hat{y} \ge 1$)，损失为0，不产生梯度；对于分类错误或间隔不足的样本，产生线性惩罚。

### 2. 优化算法 (Optimization Algorithms)
#### **目的**
根据损失函数计算得到的梯度，更新网络中的权重和偏置，以最小化损失。

#### **核心**
梯度下降 (Gradient Descent) 及其变体。

#### **自动求导 (Automatic Differentiation)**
现代深度学习框架 (TensorFlow, PyTorch) 的核心功能，能够自动计算复杂函数（如损失函数对网络参数）的梯度。主要有反向传播算法 (Backpropagation)。

#### **常见算法**
##### **SGD (Stochastic Gradient Descent)**
###### **概念**
每次更新使用一小批 (mini-batch) 样本来估计梯度并更新参数。如果批大小为1，则为纯粹的随机梯度下降。

###### **原理**
$$w_{t+1} = w_t - \eta \nabla L(w_t; x^{(i:i+B-1)}, y^{(i:i+B-1)})$$，其中 B 是批大小。期望上，小批量梯度是全批量梯度的无偏估计。

###### **优点**
计算开销小，引入的噪声有助于跳出局部最优和鞍点。

###### **缺点**
收敛速度可能较慢，参数更新方向波动较大，可能在最优点附近震荡。对学习率选择敏感。

##### **Momentum (动量法)**
###### **概念**
在 SGD 基础上引入动量项，模拟物理学中的动量概念，累积历史梯度信息以平滑更新方向。

###### **原理**
$v_t = \gamma v_{t-1} + \eta g_t$ (动量更新)
$w_{t+1} = w_t - v_t$ (参数更新)
其中 $\gamma$ 是动量系数 (通常0.9)，$g_t$ 是当前批次的梯度。

###### **作用**
加速在梯度方向一致的维度上的更新，抑制在梯度方向振荡的维度上的更新，从而加速收敛并减少振荡。

##### **Nesterov 加速梯度 (NAG / Nesterov Momentum)**
###### **概念**
Momentum 的一种改进，"提前看一步"再计算梯度。

###### **原理**
在计算梯度前，先根据当前动量"预估"下一步的位置 ($w_t - \gamma v_{t-1}$)，然后在该预估位置计算梯度 $\nabla L(w_t - \gamma v_{t-1})$。
$$v_t = \gamma v_{t-1} + \eta \nabla L(w_t - \gamma v_{t-1})$$
$$w_{t+1} = w_t - v_t$$

###### **作用**
响应更灵敏，收敛更快，通常比标准 Momentum 效果更好。

##### **AdaGrad (Adaptive Gradient Algorithm)**
###### **概念**
对不同参数使用自适应的学习率。对更新频繁的参数，学习率逐渐减小；对更新稀疏的参数，学习率相对较大。

###### **原理**
累积每个参数历史梯度的平方和 $r_t = r_{t-1} + g_t \odot g_t$，然后用 $$w_{t+1} = w_t - \frac{\eta}{\sqrt{r_t + \epsilon}} \odot g_t$$ 更新。

###### **缺点**
学习率会持续单调下降，可能导致训练后期学习率过小，过早停止学习。

##### **RMSProp (Root Mean Square Propagation)**
###### **概念**
AdaGrad 的改进，通过指数加权移动平均来累积平方梯度，防止学习率过早衰减。

###### **原理**
$$v_t = \beta v_{t-1} + (1-\beta)g_t^2$$ 然后 $$w_{t+1} = w_t - \frac{\eta}{\sqrt{v_t + \epsilon}} g_t$$ $\beta$ 是衰减率 (如0.9)。(注意：$g_t^2$ 表示 $g_t \odot g_t$)

###### **作用**
解决了 AdaGrad 学习率急剧下降的问题，在非平稳目标上表现良好。

##### **Adam (Adaptive Moment Estimation)**
###### **概念**
结合了 Momentum (一阶矩估计) 和 RMSProp (二阶矩估计) 的优点。是目前最常用的优化器之一。

###### **原理**
同时维护梯度的指数加权移动平均 (一阶矩 $m_t$) 和梯度平方的指数加权移动平均 (二阶矩 $v_t$)，并进行偏差修正。
$$m_t = \beta_1 m_{t-1} + (1-\beta_1)g_t$$
$$v_t = \beta_2 v_{t-1} + (1-\beta_2)g_t^2$$
$$\hat{m}_t = \frac{m_t}{1-\beta_1^t}$$
$$\hat{v}_t = \frac{v_t}{1-\beta_2^t}$$
$$w_{t+1} = w_t - \frac{\eta}{\sqrt{\hat{v}_t} + \epsilon} \hat{m}_t$$
 (注意：$g_t^2$ 表示 $g_t \odot g_t$)

###### **特点**
计算高效，内存需求小，对梯度缩放不变，通常是各种任务的默认首选。

##### **学习率调度 (Learning Rate Scheduling / Annealing)**
###### **概念**
在训练过程中动态调整学习率 $\eta$。

###### **原理**
初始阶段使用较大学习率加速收敛，后期减小学习率以稳定在最优解附近，避免震荡，提高最终精度。

###### **常见策略**
**StepLR**: 按设定的 epoch 数或迭代次数，将学习率乘以一个衰减因子。

**CosineAnnealingLR**: 学习率按余弦函数周期性变化。

**ExponentialLR**: 学习率按指数衰减。

**ReduceLROnPlateau**: 当监控的指标 (如验证集损失) 在一段时间内 (patience) 不再改善时，降低学习率。

**Warmup**: 在训练初期，从一个较小的学习率开始，逐步增加到预设的基础学习率，然后再按照某种策略衰减。有助于在训练初期稳定模型，避免梯度爆炸。

### 3. 正则化 (Regularization)
#### **目的**
防止模型过拟合 (overfitting)，提高模型在未见过数据上的泛化能力 (generalization)。

#### **常见方法**
##### **L1 正则化 (Lasso Regression)**
###### **概念**
在损失函数中加入参数的 L1 范数惩罚项 $\lambda \|w\|_1 = \lambda \sum_i |w_i|$。

###### **原理**
倾向于产生稀疏权重 (使一部分权重变为0)，从而实现特征选择的效果。

##### **L2 正则化 (Ridge Regression / Weight Decay)**
###### **概念**
在损失函数中加入参数的 L2 范数平方惩罚项 $\lambda \|w\|_2^2 = \lambda \sum_i w_i^2$。

###### **原理**
惩罚较大的权重值，使得权重分布更平滑，防止模型过度依赖某些特征。这是最常用的正则化方法之一。

##### **Dropout**
###### **概念**
在训练阶段，以一定的概率 $p$ 随机"丢弃"(暂时移除)一部分神经元及其连接。在测试阶段，所有神经元都保留，但其输出值会乘以保留概率 $p$ (或者在训练时进行反向缩放，即输出除以 $p$)。

###### **原理**
**模型集成思想**: 每次丢弃不同的神经元组合，相当于训练了多个不同的子网络，测试时取平均效果。

**打破共适应**: 防止神经元之间产生复杂的共适应关系 (co-adaptation)，使得每个神经元学习到更鲁棒的特征。

##### **Early Stopping**
###### **概念**
在训练过程中，持续监控模型在验证集上的性能 (如损失或准确率)。当验证集性能在连续若干个周期 (patience) 内不再提升甚至开始下降时，提前终止训练。

###### **原理**
模型在训练集上损失持续下降，但在验证集上损失开始上升的点，通常是过拟合开始的信号。保存验证集性能最佳时的模型。

##### **数据增强 (Data Augmentation)**
###### **概念**
通过对训练数据进行各种变换（如图像的旋转、裁剪、缩放、颜色抖动；文本的同义词替换、随机插入/删除等）来人为增加训练样本的数量和多样性。

###### **原理**
使模型学习到对各种扰动不变的特征，提高其泛化能力和鲁棒性。

##### **Batch Normalization (本身也有正则化效果)**
见下文归一化部分，其引入的噪声有时也能起到正则化作用。

### 4. 归一化 (Normalization)
#### **目的**
##### **加速收敛**
使不同层或不同特征的输入分布更一致，有助于优化算法更快找到最优解。

##### **缓解内部协变量偏移 (Internal Covariate Shift)**
训练过程中，由于前层参数的更新，导致后续层输入数据的分布发生变化，使得学习变慢。归一化可以减弱这种影响。

##### **允许使用更大学习率**
归一化后损失函数的曲面更平滑。

##### **轻微正则化效果**
(尤其是 BatchNorm) 对小批量数据的均值和方差的估计带有噪声。

#### **常见类型**
##### **BatchNorm (Batch Normalization)**
###### **概念**
对每个 mini-batch 内的激活值按通道 (channel-wise) 进行归一化 (减去批次均值，除以批次标准差)，然后通过可学习的缩放参数 ($\gamma$) 和平移参数 ($\beta$) 来恢复其表达能力。

###### **原理**
$$\hat{x}^{(k)} = \frac{x^{(k)} - \mathbb{E}[x^{(k)}]}{\sqrt{\text{Var}[x^{(k)}] + \epsilon}}$$ 然后 $$y^{(k)} = \gamma^{(k)} \hat{x}^{(k)} + \beta^{(k)}$$ 训练时使用当前批次的均值和方差，测试时使用训练期间累积的全局移动平均均值和方差。

###### **位置**
通常放在卷积层或全连接层之后，激活函数之前 (有时也在激活函数之后)。

###### **缺点**
对批次大小 (batch size) 敏感，小批次时估计的均值和方差不准确，影响效果。不适用于某些序列模型（如RNN中每个时间步的统计量不同）。

##### **LayerNorm (Layer Normalization)**
###### **概念**
对单个样本的所有特征 (在特征维度上) 进行归一化，而不是在批次维度上。

###### **原理**
计算单个样本内所有激活值的均值和方差进行归一化。与批次大小无关。

###### **应用**
在 RNN、Transformer 等处理序列数据或小批量场景中更稳定和常用。

##### **InstanceNorm (Instance Normalization)**
###### **概念**
对单个样本的每个通道独立进行归一化。可以看作是批大小为1的 BatchNorm。

###### **原理**
计算单个样本、单个通道内激活值的均值和方差。

###### **应用**
常用于图像风格迁移等任务，因为它能消除特定图像的对比度信息，关注内容结构。

##### **GroupNorm (Group Normalization)**
###### **概念**
将通道分成若干组 (groups)，在每组内进行归一化。是 BatchNorm 和 LayerNorm 的一种折衷。

###### **原理**
将通道维度分成 G 组，每组包含 C/G 个通道，然后在这些 C/G 个通道上对每个样本计算均值和方差。

###### **优点**
对批次大小不敏感，性能稳定，尤其在小批次下优于 BatchNorm。

## 三、经典架构 (Classic Architectures)

### 1. 感知机 (Perceptron, 1958)
#### **概念**
最早的神经网络模型之一，由 Frank Rosenblatt 提出。单层结构，只能学习线性可分的问题。

#### **结构**
输入层直接连接到输出层，输出是输入的加权和经过阶跃函数 (step function)。

#### **局限性**
无法解决简单的 XOR 问题 (异或问题)，这是因为它不能表示非线性决策边界。这一局限性催生了多层感知机 (MLP) 的发展。

### 2. 多层感知机 (MLP, Multi-layer Perceptron)
#### **概念**
具有一个或多个隐藏层的前馈神经网络，克服了感知机无法学习非线性边界的局限。

#### **结构**
输入层 -> 一个或多个隐藏层 -> 输出层。各层之间全连接，使用非线性激活函数。

#### **计算流程**
每一层：$h^{(l)} = \sigma(W^{(l)} \cdot h^{(l-1)} + b^{(l)})$，其中 $h^{(0)} = x$ 是输入，$\sigma$ 是激活函数。

#### **应用**
简单分类与回归问题，也可作为其他复杂架构的组件。

### 3. 卷积神经网络 (CNN, Convolutional Neural Network)
#### **核心思想**
利用卷积操作捕获空间局部特征，大幅减少参数量，并具有平移不变性，特别适合处理具有空间结构的数据（如图像）。

#### **基本组件**
##### **卷积层 (Convolutional Layer)**
###### **概念**
通过滑动窗口 (卷积核) 对输入特征图执行卷积操作，提取局部特征。

###### **参数**
**卷积核大小 (kernel size)**: 例如 3×3, 5×5, 7×7，定义感受野大小。

**卷积核数量 (filters/channels)**: 每个卷积核学习不同的特征检测器。

**步长 (stride)**: 卷积核滑动的步长，控制输出特征图的下采样率。

**填充 (padding)**: 在输入周围添加像素（通常是零），保持输出尺寸。

###### **作用**
提取层次化的视觉特征，随着网络深度增加，从边缘、纹理到部件、对象的不同抽象级别。

##### **池化层 (Pooling Layer)**
###### **概念**
对特征图进行区域汇总，降低空间维度，提取显著特征，同时减少计算量和参数量。

###### **类型**
**最大池化 (Max Pooling)**: 取窗口内最大值，强调最显著特征。

**平均池化 (Average Pooling)**: 取窗口内平均值，保留更多背景信息。

**全局池化 (Global Pooling)**: 对整个特征图应用池化，常用于 CNN 末端将特征图转为特征向量。

###### **作用**
降低维度、提高平移不变性、减少计算量、防止过拟合。

##### **全连接层 (Fully Connected Layer)**
###### **概念**
通常位于 CNN 末端，将卷积层/池化层提取的特征映射到最终输出（如类别概率）。

###### **作用**
整合高层特征，执行最终任务（分类、回归等）。

#### **经典 CNN 架构**
##### **LeNet-5 (1998)**
###### **贡献**
Yann LeCun 提出的开创性 CNN 架构，用于手写数字识别 (MNIST)，奠定了现代 CNN 的基础。

###### **特点**
两个卷积层和池化层的交替，后接三个全连接层。使用 sigmoid/tanh 激活函数。

##### **AlexNet (2012)**
###### **贡献**
2012 年 ImageNet 竞赛冠军，引发了深度学习革命，证明了深度 CNN 在大规模视觉任务上的强大性能。

###### **创新点**
- 更深的架构：5个卷积层，3个全连接层
- ReLU 激活函数取代 sigmoid/tanh
- Dropout 防止过拟合
- 数据增强
- GPU 加速训练（双 GPU 并行）

##### **VGGNet (2014)**
###### **贡献**
Oxford 大学 VGG 组提出，以简洁统一的架构设计著称，展示了深度对性能的重要性。

###### **创新点**
- 使用小尺寸卷积核 (3×3)，通过堆叠多层获得较大感受野，同时参数更少
- 深度达到 16-19 层
- 简洁一致的架构设计：逐步加倍通道数，同时通过池化减半空间尺寸

##### **GoogLeNet/Inception (2014)**
###### **贡献**
Google 提出，引入 Inception 模块，大幅减少参数量同时保持高性能。

###### **创新点**
- Inception 模块：并行使用不同尺寸的卷积核 (1×1, 3×3, 5×5) 和池化操作，捕获不同尺度的特征
- 1×1 卷积用于降维，减少计算量
- 网络加深至 22 层，但参数量仅为 AlexNet 的 1/12
- 辅助分类器缓解梯度消失
- 全局平均池化代替全连接层

##### **ResNet (2015)**
###### **贡献**
微软研究院提出，通过残差连接解决了深度网络的梯度消失/爆炸问题，使训练极深网络 (100+ 层) 成为可能。

###### **创新点**
- 残差块 (Residual Block)：通过跳跃连接 (skip connection) 传递未修改的输入：$F(x) + x$，让网络学习残差映射
- 解决了深度增加反而性能下降的退化问题
- 成功训练 152 层网络
- 引入瓶颈结构 (bottleneck design)，通过 1×1 卷积降维-升维，减少参数

##### **DenseNet (2017)**
###### **贡献**
每层与之前所有层直接相连，增强特征重用、缓解梯度消失、提高参数效率。

###### **创新点**
- 密集连接：每层输入包含所有前面层的特征图 (concatenation 而非 addition)
- 强特征重用
- 缓解梯度消失
- 显著减少参数数量

##### **EfficientNet (2019)**
###### **贡献**
Google 提出，通过复合缩放方法同时扩展网络的宽度、深度和分辨率，在准确率和效率之间取得最佳平衡。

###### **创新点**
- 复合缩放：根据计算资源约束，协调缩放网络宽度 (通道数)、深度 (层数) 和分辨率 (输入大小)
- 从小型高效基础网络 (EfficientNet-B0) 开始，使用神经架构搜索 (NAS) 设计
- 在同等计算复杂度下，大幅提高准确率

### 4. 循环神经网络 (RNN, Recurrent Neural Network)
#### **核心思想**
引入循环连接处理序列数据，利用隐藏状态 (hidden state) 保存历史信息。特别适合处理时序数据、文本等变长序列输入。

#### **基本结构**
##### **简单 RNN (Vanilla RNN)**
###### **基本公式**
$$h_t = \sigma(W_{hx} x_t + W_{hh} h_{t-1} + b_h)$$
$$y_t = \phi(W_{yh} h_t + b_y)$$
其中 $h_t$ 是时间步 t 的隐藏状态，$x_t$ 是输入，$y_t$ 是输出，$\sigma$ 和 $\phi$ 是激活函数。

###### **特点**
- 参数共享：在所有时间步使用相同的权重矩阵
- 递归计算：当前隐藏状态依赖于前一时间步的隐藏状态
- 可变长度输入：能处理不同长度的序列

###### **问题**
- 梯度消失/爆炸：通过时间反向传播 (BPTT) 时，梯度连乘导致长期依赖难以学习
- 长序列上表现欠佳：难以保留长距离信息

##### **长短期记忆网络 (LSTM, Long Short-Term Memory)**
###### **动机**
解决 vanilla RNN 无法捕获长距离依赖的问题。

###### **核心组件**
**遗忘门 (Forget Gate)**: 控制丢弃多少前一状态的信息
$$f_t = \sigma(W_f \cdot [h_{t-1}, x_t] + b_f)$$

**输入门 (Input Gate)**: 控制多少新信息加入到细胞状态
$$i_t = \sigma(W_i \cdot [h_{t-1}, x_t] + b_i)$$
$$\tilde{C}_t = \tanh(W_C \cdot [h_{t-1}, x_t] + b_C)$$

**细胞状态 (Cell State)**: 通过线性交互传递信息，减轻梯度消失
$$C_t = f_t \odot C_{t-1} + i_t \odot \tilde{C}_t$$

**输出门 (Output Gate)**: 控制多少细胞状态信息输出
$$o_t = \sigma(W_o \cdot [h_{t-1}, x_t] + b_o)$$
$$h_t = o_t \odot \tanh(C_t)$$

###### **优点**
- 解决了梯度消失问题
- 能更好处理长距离依赖
- 能管理信息流，选择性记忆或遗忘

##### **门控循环单元 (GRU, Gated Recurrent Unit)**
###### **动机**
简化 LSTM 结构，减少参数同时保持类似性能。

###### **核心组件**
**更新门 (Update Gate)**: 控制前一隐藏状态与新计算状态的融合比例
$$z_t = \sigma(W_z \cdot [h_{t-1}, x_t] + b_z)$$

**重置门 (Reset Gate)**: 控制前一隐藏状态影响新候选隐藏状态的程度
$$r_t = \sigma(W_r \cdot [h_{t-1}, x_t] + b_r)$$

**隐藏状态更新**
$$\tilde{h}_t = \tanh(W \cdot [r_t \odot h_{t-1}, x_t] + b)$$
$$h_t = (1 - z_t) \odot h_{t-1} + z_t \odot \tilde{h}_t$$

###### **优点**
- 参数更少 (相比 LSTM)
- 训练更快，适合中短序列
- 性能通常与 LSTM 相当

#### **RNN 架构变体**
##### **双向 RNN (Bidirectional RNN)**
###### **概念**
同时从正向和反向处理序列，结合两个方向的信息进行预测。特别适合需要同时利用前后文信息的任务 (如词性标注或命名实体识别)。

###### **结构**
包含两个独立 RNN：一个从左到右，一个从右到左。最终输出结合两者的隐藏状态。

##### **深度 RNN (Deep RNN / Stacked RNN)**
###### **概念**
多层 RNN 堆叠，每一层的输出作为下一层的输入。不同层次捕获不同抽象级别的特征。

###### **优点**
增强模型表达能力，学习更复杂序列模式。

##### **编码器-解码器 (Encoder-Decoder / Sequence-to-Sequence)**
###### **概念**
由编码器和解码器两部分组成：编码器将输入序列编码为固定长度的上下文向量；解码器根据该上下文向量生成输出序列。

###### **应用**
机器翻译、文本摘要、聊天机器人等需要序列到序列映射的任务。

###### **问题**
基础版本中，将整个输入序列压缩成单一固定长度的上下文向量，信息瓶颈严重，限制了处理长序列的能力。

##### **注意力机制 (Attention Mechanism)**
###### **动机**
解决编码器-解码器架构的信息瓶颈问题，允许解码器选择性地关注输入序列的不同部分。

###### **原理**
为源序列中每个位置分配注意力权重，根据权重加权求和得到上下文向量。注意力权重通常基于查询向量 (当前解码器状态) 与键向量 (编码器各状态) 的相似度。

###### **类型**
**加性注意力 (Additive/Bahdanau Attention)**: $\alpha_{ij} \propto \exp(v^T \tanh(W_1 h_i + W_2 s_j))$

**点积注意力 (Dot-Product/Luong Attention)**: $\alpha_{ij} \propto \exp(h_i^T s_j)$

**缩放点积注意力 (Scaled Dot-Product)**: $\alpha_{ij} \propto \exp(\frac{h_i^T s_j}{\sqrt{d}})$，其中 d 是向量维度。

###### **贡献**
为 Transformer 架构的发展奠定了基础。

### 5. Transformer
#### **核心思想**
完全基于注意力机制的序列转换模型，摒弃了 RNN 和 CNN 的循环或卷积结构，实现了更高效的并行计算和更好的长距离依赖建模能力。

#### **基本组件**
##### **自注意力 (Self-Attention)**
###### **概念**
序列中的每个元素都与同一序列中的所有元素（包括自身）计算注意力，捕获序列内部的依赖关系。

###### **计算步骤**
1. 线性变换生成查询 (Q)、键 (K) 和值 (V) 矩阵
   $$Q = X W^Q, K = X W^K, V = X W^V$$
2. 计算注意力分数 (缩放点积注意力)
   $$\text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V$$
   其中 $d_k$ 是键向量的维度，用于缩放以防止梯度消失问题。

###### **优点**
- 全局感受野：直接建立任意两个位置之间的依赖关系
- 并行计算：不像 RNN 需要顺序计算
- 可解释性：注意力权重可视化表明模型关注的部分

##### **多头注意力 (Multi-Head Attention)**
###### **概念**
并行运行多个自注意力"头"，每个头关注输入的不同表示子空间，然后合并各头的结果。

###### **计算**
$$\text{MultiHead}(Q, K, V) = \text{Concat}(\text{head}_1, \ldots, \text{head}_h)W^O$$
其中 $\text{head}_i = \text{Attention}(QW_i^Q, KW_i^K, VW_i^V)$

###### **作用**
增强模型捕获不同类型模式的能力，如语法和语义特征。

##### **位置编码 (Positional Encoding)**
###### **目的**
由于自注意力本身不包含位置信息，需要额外的位置编码注入序列中的位置信息。

###### **实现**
使用正弦和余弦函数生成的位置编码：
$$PE_{(pos, 2i)} = \sin(pos / 10000^{2i/d_{model}})$$
$$PE_{(pos, 2i+1)} = \cos(pos / 10000^{2i/d_{model}})$$
其中 $pos$ 是位置，$i$ 是维度。

###### **特点**
- 允许模型外推到训练中未见过的序列长度
- 相对位置的差值在不同位置上表现出相似的模式

##### **前馈神经网络 (Feed Forward Network)**
###### **结构**
两个线性变换，中间带有 ReLU 激活函数：
$$\text{FFN}(x) = \max(0, xW_1 + b_1)W_2 + b_2$$

###### **作用**
引入非线性变换，增强模型表达能力。

##### **残差连接 (Residual Connection) 和层归一化 (Layer Normalization)**
###### **残差连接**
将子层输入直接加到其输出上：$x + \text{Sublayer}(x)$，缓解深度网络的梯度问题。

###### **层归一化**
对每个样本特征进行归一化，稳定深度模型训练。

#### **Transformer 架构**
##### **编码器 (Encoder)**
###### **结构**
N 个相同层的堆叠 (原论文 N=6)，每层包含：
- 多头自注意力子层
- 位置全连接前馈网络子层
两个子层都有残差连接和层归一化。

###### **作用**
将输入序列转换为连续表示。

##### **解码器 (Decoder)**
###### **结构**
同样是 N 个相同层的堆叠，每层包含：
- 掩码多头自注意力子层 (防止看到未来信息)
- 对编码器输出的多头注意力子层
- 位置全连接前馈网络子层
同样使用残差连接和层归一化。

###### **作用**
根据编码器输出和已生成的部分，逐步生成输出序列。

#### **Transformer 的影响**
##### **NLP 革命**
促成了 BERT、GPT、T5 等预训练模型，彻底改变了 NLP 技术栈。

##### **多模态应用**
扩展到计算机视觉 (ViT)、音频处理，实现跨模态学习。

##### **可扩展性**
模型结构允许高效的并行计算，易于扩展到大规模数据和超大模型参数。

## 四、特殊任务架构 (Special Task Architectures)

### 1. 生成式对抗网络 (GAN, Generative Adversarial Network)
#### **核心思想**
通过博弈论框架训练生成器和判别器两个网络：生成器尝试创建逼真样本，判别器尝试区分真实与生成样本。相互竞争促使生成器产生高质量样本。

#### **基本结构**
##### **生成器 G (Generator)**
###### **功能**
将随机噪声 z 映射到数据空间，生成逼真样本。

###### **结构**
通常是转置卷积 (反卷积) 或上采样+卷积的网络，逐步将低维噪声转换为高维数据。

###### **训练目标**
最小化判别器正确分类生成样本的能力：$\min_G \mathbb{E}_{z \sim p_z(z)}[\log(1 - D(G(z)))]$
或等效地，最大化判别器将生成样本错分为真实的概率：$\max_G \mathbb{E}_{z \sim p_z(z)}[\log(D(G(z)))]$

##### **判别器 D (Discriminator)**
###### **功能**
区分真实样本和生成器产生的样本。

###### **结构**
通常是标准分类网络，如 CNN，输出样本为真实的概率。

###### **训练目标**
最大化判别能力：$\max_D \mathbb{E}_{x \sim p_{data}(x)}[\log D(x)] + \mathbb{E}_{z \sim p_z(z)}[\log(1 - D(G(z)))]$

#### **训练过程**
##### **对抗训练**
###### **零和博弈**
生成器和判别器通过 min-max 博弈进行训练：
$$\min_G \max_D V(D, G) = \mathbb{E}_{x \sim p_{data}(x)}[\log D(x)] + \mathbb{E}_{z \sim p_z(z)}[\log(1 - D(G(z)))]$$

###### **交替优化**
- 固定 G，更新 D 几步
- 固定 D，更新 G 一步
- 重复上述过程

##### **挑战**
###### **训练不稳定**
平衡 G 和 D 的训练困难，容易出现梯度消失、模式崩溃等问题。

###### **模式崩溃 (Mode Collapse)**
生成器仅产生有限种类的样本，无法覆盖整个数据分布。

###### **收敛判断困难**
没有明确的损失指标判断收敛。

##### **改进技术**
###### **Wasserstein GAN (WGAN)**
用 Wasserstein 距离替代 JS 散度，提供更稳定的梯度。

###### **WGAN-GP**
WGAN 的改进，用梯度惩罚替代权重裁剪，进一步提高稳定性。

###### **条件 GAN (Conditional GAN)**
将类别标签作为额外输入提供给 G 和 D，控制生成过程。

###### **循环 GAN (CycleGAN)**
无需配对数据的域间转换，通过循环一致性损失实现。

###### **StyleGAN**
引入风格转换思想控制生成特征，产生高质量、可控的图像生成。

#### **应用**
##### **图像生成**
逼真人脸、场景、艺术作品等生成。

##### **图像转换**
风格迁移、超分辨率、图像修复、草图转图像等。

##### **数据增强**
生成合成训练数据，增强模型泛化能力。

### 2. 变分自编码器 (VAE, Variational Autoencoder)
#### **核心思想**
结合自编码器和变分推断，学习数据的隐变量概率分布，而非确定性表示，实现概率生成模型。

#### **与传统自编码器的区别**
##### **传统自编码器**
###### **目标**
将输入压缩为紧凑编码，然后通过解码器重建，学习有效的数据表示。

###### **编码形式**
生成确定性的隐空间点 z。

##### **变分自编码器**
###### **目标**
学习数据的生成概率模型，潜变量 z 的分布，而非单点表示。

###### **编码形式**
编码器输出均值向量 μ 和标准差向量 σ，定义潜变量的高斯分布。

#### **数学原理**
##### **目标函数 (ELBO)**
###### **重建损失**
衡量输入和重建输出的相似度：$\mathbb{E}_{z \sim q_\phi(z|x)}[\log p_\theta(x|z)]$

###### **KL 散度**
确保编码分布接近先验分布：$D_{KL}(q_\phi(z|x) || p(z))$，其中 $p(z)$ 通常是标准正态分布 $\mathcal{N}(0, I)$。

###### **总损失**
最大化证据下界 (ELBO)：$\mathcal{L}(\theta, \phi; x) = \mathbb{E}_{z \sim q_\phi(z|x)}[\log p_\theta(x|z)] - D_{KL}(q_\phi(z|x) || p(z))$

#### **架构组件**
##### **编码器**
###### **功能**
将输入 x 映射到潜变量分布参数 μ 和 σ。

###### **结构**
通常是 MLP 或 CNN 结构，输出层生成 μ 和 logσ (取指数得到 σ)。

##### **重参数化技巧**
###### **目的**
使采样过程可导，允许通过反向传播训练。

###### **方法**
$z = \mu + \sigma \odot \epsilon$，其中 $\epsilon \sim \mathcal{N}(0, I)$ 是标准正态采样。

##### **解码器**
###### **功能**
将潜变量 z 映射回数据空间，重建输入。

###### **结构**
与编码器对称或结构相似的神经网络。

#### **应用**
##### **生成新样本**
从先验分布采样 z，通过解码器生成新数据。

##### **学习连续表示**
潜变量空间连续，支持潜变量插值，生成平滑过渡的样本。

##### **异常检测**
重建误差可作为异常分数。

##### **条件生成**
加入条件信息控制生成过程。

### 3. 扩散模型 (Diffusion Models)
#### **核心思想**
模拟逐步向数据中添加噪声的前向扩散过程，然后训练模型学习反向去噪过程，逐步恢复数据。属于基于分数的生成模型。

#### **算法流程**
##### **前向扩散过程**
###### **概念**
逐步给数据 x₀ 添加高斯噪声，形成马尔可夫链 x₁, x₂, ..., xₜ，直到变成近似纯噪声。

###### **数学表述**
$$q(x_t|x_{t-1}) = \mathcal{N}(x_t; \sqrt{1-\beta_t}x_{t-1}, \beta_t\mathbf{I})$$
其中 $\beta_t$ 是噪声调度参数，随 t 递增。

##### **反向去噪过程**
###### **目标**
学习从噪声中恢复数据的条件概率 $p_\theta(x_{t-1}|x_t)$。

###### **参数化**
将 $p_\theta(x_{t-1}|x_t)$ 参数化为高斯分布，预测噪声或去噪后的数据。

##### **训练目标**
###### **变分下界**
优化的目标是证据下界，简化后等价于预测添加的噪声。

###### **损失函数**
$$L_{simple} = \mathbb{E}_{t,x_0,\epsilon}[||\epsilon - \epsilon_\theta(x_t, t)||^2]$$
其中 $\epsilon$ 是实际添加的噪声，$\epsilon_\theta$ 是模型预测的噪声。

#### **特性与优势**
##### **稳定训练**
与 GAN 相比训练更稳定，不存在生成器-判别器平衡问题。

##### **高质量采样**
生成样本多样性与质量兼顾，不易发生模式崩溃。

##### **灵活引导**
支持条件生成、分类器引导等技术控制生成。

#### **代表模型**
##### **DDPM (Denoising Diffusion Probabilistic Models)**
扩散模型开创性工作，提出基本框架。

##### **DDIM (Denoising Diffusion Implicit Models)**
加速采样过程的非马尔可夫扩散模型。

##### **Stable Diffusion**
采用潜变量扩散，在低维潜空间操作，提高计算效率和生成质量的文本到图像模型。

#### **应用**
##### **图像生成**
高质量、多样性图像生成。

##### **文本到图像生成**
如 DALL-E 2, Midjourney, Stable Diffusion 等。

##### **音频生成**
语音、音乐生成。

### 4. 自回归模型 (Autoregressive Models)
#### **核心思想**
将复杂高维数据的联合分布分解为多个条件分布的乘积，基于先前生成的元素逐步生成后续元素。如文字接龙，每次预测下一个词。

#### **概率分解**
##### **链式法则**
$$p(x) = p(x_1) \cdot p(x_2|x_1) \cdot p(x_3|x_1,x_2) \cdots p(x_n|x_1,x_2,...,x_{n-1})$$

##### **数学表述**
$$p(x) = \prod_{t=1}^{n} p(x_t|x_{<t})$$

#### **训练与采样**
##### **训练过程**
###### **目标**
最大化所有条件概率的对数似然。

###### **损失函数**
对于语言模型，通常是交叉熵损失，预测序列中每个位置的下一个标记。

##### **采样过程**
###### **自回归生成**
逐元素生成：采样 x₁，然后条件于 x₁ 采样 x₂，依此类推。

###### **温度控制**
控制生成的多样性 vs. 确定性。

#### **代表模型**
##### **语言模型**
###### **GPT 系列**
仅使用 Transformer 解码器的大规模语言模型，代表当今最先进的自回归语言模型。

###### **LLaMA 等开源模型**
开源社区扩展的自回归语言模型。

##### **图像模型**
###### **PixelCNN**
基于 CNN 的自回归图像模型，逐像素生成。

###### **ImageGPT**
将 GPT 自回归思想应用于图像生成。

##### **音频模型**
###### **WaveNet**
用于语音合成的自回归音频模型。

###### **Jukebox**
OpenAI 的音乐生成模型。

#### **优缺点**
##### **优点**
###### **可控性高**
容易引入条件信息控制生成。

###### **理论上可表达任意复杂分布**
无需对数据分布做简化假设。

##### **缺点**
###### **生成速度慢**
顺序生成过程难以并行化，尤其对高维数据。

###### **潜在的错误累积**
生成过程中的错误可能影响后续生成，造成累积误差。

### 5. 流模型 (Flow-based Models)
#### **核心思想**
构建数据分布和简单分布（如高斯分布）之间的可逆变换，通过一系列可逆函数组合，实现两者之间的精确映射和概率计算。

#### **数学基础**
##### **变量变换定理**
###### **概念**
如果 z = f(x) 是可逆的，则 $p_X(x) = p_Z(f(x))\left|\det\frac{\partial f(x)}{\partial x}\right|$

###### **流设计要点**
- 变换必须可逆 (双射)
- 雅可比行列式计算必须高效
- 变换应足够灵活以表达复杂分布

#### **架构特点**
##### **标准化流 (Normalizing Flows)**
###### **原理**
通过一系列可逆变换 $z = f_K \circ ... \circ f_2 \circ f_1(x)$ 将复杂分布转换为简单分布。

###### **特点**
明确的对数似然，支持精确推断和生成。

##### **常见基本模块**
###### **仿射耦合层 (Affine Coupling Layer)**
将输入切分为两部分，一部分保持不变，另一部分进行仿射变换。
$$y_{1:d} = x_{1:d}$$
$$y_{d+1:D} = x_{d+1:D} \odot \exp(s(x_{1:d})) + t(x_{1:d})$$
其中 s 和 t 是任意神经网络。

###### **可逆 1x1 卷积**
替代简单的置换操作，增加表达能力，仍保持可逆性。

#### **代表模型**
##### **NICE/RealNVP**
最早的实用流模型，引入耦合层设计。

##### **Glow**
改进的流模型，增加了可逆 1x1 卷积和线性变换，提高表达能力。

##### **Flow++**
通过自回归变换增强流模型，结合自回归和流的优势。

#### **优缺点**
##### **优点**
###### **精确似然计算**
可直接计算对数似然，便于模型评估和训练。

###### **快速推断与生成**
生成和推断过程都可并行化，效率高。

##### **缺点**
###### **计算效率与表达能力权衡**
可逆约束和雅可比行列式计算限制了模型设计灵活性。

###### **难以处理离散数据**
主要设计用于连续空间，处理离散数据需特殊技巧。

## 五、深度学习中的关键概念

### 1. 损失函数 (Loss Functions)
#### **概念**
度量模型预测值与真实值之间的差异，是优化的目标函数。不同任务和数据分布特点需要选择合适的损失函数。

#### **回归损失**
##### **均方误差 (MSE, Mean Squared Error)**
###### **定义**
$$\mathcal{L}_{MSE} = \frac{1}{n}\sum_{i=1}^{n}(y_i - \hat{y}_i)^2$$

###### **特点**
对异常值敏感，惩罚大误差；在目标服从高斯分布时是最大似然估计。

##### **平均绝对误差 (MAE, Mean Absolute Error)**
###### **定义**
$$\mathcal{L}_{MAE} = \frac{1}{n}\sum_{i=1}^{n}|y_i - \hat{y}_i|$$

###### **特点**
对异常值不那么敏感，在目标服从拉普拉斯分布时是最大似然估计。

##### **Huber 损失**
###### **定义**
$$\mathcal{L}_{\delta}(y, \hat{y}) = \begin{cases}
\frac{1}{2}(y - \hat{y})^2 & \text{for } |y - \hat{y}| \leq \delta \\
\delta(|y - \hat{y}| - \frac{1}{2}\delta) & \text{otherwise}
\end{cases}$$

###### **特点**
结合 MSE 和 MAE 优点，小误差使用平方损失，大误差使用线性损失，对异常值更鲁棒。

#### **分类损失**
##### **交叉熵损失 (Cross Entropy Loss)**
###### **二分类**
$$\mathcal{L}_{BCE} = -\frac{1}{n}\sum_{i=1}^{n}[y_i\log(\hat{y}_i) + (1-y_i)\log(1-\hat{y}_i)]$$

###### **多分类**
$$\mathcal{L}_{CE} = -\frac{1}{n}\sum_{i=1}^{n}\sum_{c=1}^{C}y_{i,c}\log(\hat{y}_{i,c})$$
其中 $y_{i,c}$ 是独热编码的真实标签，$\hat{y}_{i,c}$ 是预测的类别概率。

##### **焦点损失 (Focal Loss)**
###### **定义**
$$\mathcal{L}_{FL} = -\frac{1}{n}\sum_{i=1}^{n}(1-\hat{y}_i)^{\gamma}y_i\log(\hat{y}_i)$$
其中 $\gamma$ 是调制因子 (通常取2)。

###### **特点**
降低容易样本的损失权重，更关注难分类样本，适用于类别不平衡问题。

##### **KL 散度 (Kullback-Leibler Divergence)**
###### **定义**
$$\mathcal{L}_{KL} = \sum_{c=1}^{C}y_c\log\frac{y_c}{\hat{y}_c}$$

###### **特点**
衡量两个概率分布的差异，用于知识蒸馏等场景。

#### **特殊任务损失**
##### **对比损失 (Contrastive Loss)**
###### **定义**
$$\mathcal{L}_{cont} = \frac{1}{2}(1-Y)D^2 + \frac{1}{2}Y\max(0, m-D)^2$$
其中 $D$ 是特征距离，$Y$ 是相似性标签 (0表示相似，1表示不相似)，$m$ 是边界参数。

###### **用途**
学习有判别力的嵌入表示，用于度量学习、人脸识别等。

##### **三元组损失 (Triplet Loss)**
###### **定义**
$$\mathcal{L}_{triplet} = \max(0, D(a,p) - D(a,n) + margin)$$
其中 $a$ 是锚点样本，$p$ 是正样本，$n$ 是负样本，$D$ 是距离函数。

###### **用途**
学习距离度量，使同类样本更靠近，不同类样本更远离。

### 2. 评估指标 (Evaluation Metrics)
#### **分类指标**
##### **准确率 (Accuracy)**
###### **定义**
$$\text{Accuracy} = \frac{\text{正确预测数}}{\text{总样本数}}$$

###### **局限性**
在类别不平衡数据上可能产生误导。

##### **精确率 (Precision)**
###### **定义**
$$\text{Precision} = \frac{\text{TP}}{\text{TP} + \text{FP}}$$

###### **含义**
阳性预测的准确率，衡量模型的"纯度"。

##### **召回率 (Recall / Sensitivity)**
###### **定义**
$$\text{Recall} = \frac{\text{TP}}{\text{TP} + \text{FN}}$$

###### **含义**
正例覆盖率，衡量模型的"完备性"。

##### **F1 分数**
###### **定义**
$$\text{F1} = \frac{2 \times \text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}$$

###### **特点**
精确率和召回率的调和平均，综合考虑两者。

##### **ROC 曲线和 AUC**
###### **ROC 曲线**
以假阳性率 (FPR) 为横轴，真阳性率 (TPR) 为纵轴的曲线，展示不同阈值下的模型表现。

###### **AUC (Area Under Curve)**
ROC 曲线下的面积，范围 [0,1]，越高越好，表示模型区分正负类的能力。

#### **回归指标**
##### **均方根误差 (RMSE)**
###### **定义**
$$\text{RMSE} = \sqrt{\frac{1}{n}\sum_{i=1}^{n}(y_i - \hat{y}_i)^2}$$

###### **特点**
比 MSE 更易解释，单位与目标变量一致。

##### **平均绝对百分比误差 (MAPE)**
###### **定义**
$$\text{MAPE} = \frac{100\%}{n}\sum_{i=1}^{n}|\frac{y_i - \hat{y}_i}{y_i}|$$

###### **特点**
以百分比形式表示误差，但在真实值接近零时不稳定。

##### **决定系数 (R²)**
###### **定义**
$$\text{R}^2 = 1 - \frac{\sum_{i=1}^{n}(y_i - \hat{y}_i)^2}{\sum_{i=1}^{n}(y_i - \bar{y})^2}$$

###### **含义**
模型解释的方差比例，范围通常在 [0,1]，越接近1表示模型越好。

#### **专用任务指标**
##### **目标检测**
###### **IoU (Intersection over Union)**
交并比，衡量预测边界框与真实边界框的重叠程度。

###### **mAP (mean Average Precision)**
不同 IoU 阈值和/或类别下的平均精确率，常用指标如 COCO mAP@[.5:.95]。

##### **图像分割**
###### **Dice 系数**
$$\text{Dice} = \frac{2|X \cap Y|}{|X| + |Y|}$$
其中 X 和 Y 分别是预测和真实分割图。

###### **Jaccard 指数 / IoU**
分割掩码的交集除以并集。

##### **自然语言处理**
###### **困惑度 (Perplexity)**
$$\text{PPL} = \exp(-\frac{1}{N}\sum_{i=1}^{N}\log p(x_i))$$
衡量语言模型预测下一个词的能力，越低越好。

###### **BLEU / ROUGE**
衡量生成文本与参考文本的相似度，基于 n-gram 匹配。

##### **推荐系统**
###### **NDCG (Normalized Discounted Cumulative Gain)**
考虑排序位置的推荐质量指标，适用于有多级相关性的场景。

###### **点击率 (CTR) / 转化率 (CVR)**
$\text{CTR} = \frac{\text{点击数}}{\text{展示数}}$，实际业务中常用的在线评估指标。

### 3. 优化挑战与对策
#### **梯度消失/爆炸**
##### **原因**
###### **激活函数**
sigmoid/tanh 在极端输入值饱和区梯度接近零。

###### **网络深度**
反向传播中连续的矩阵乘法导致梯度指数级缩小或扩大。

##### **解决方案**
###### **激活函数选择**
使用 ReLU 及其变体，避免饱和区。

###### **参数初始化**
精心设计的初始化方法 (如 Xavier/Glorot, He 初始化) 保持方差稳定。

###### **批归一化**
在每一层输出进行归一化，控制数值范围。

###### **残差连接**
创建梯度的捷径，缓解深层梯度问题。

###### **梯度裁剪**
防止梯度爆炸，设置梯度更新的最大范数。

#### **过拟合 / 欠拟合**
##### **表现**
###### **过拟合**
训练误差低，验证/测试误差高，模型过于复杂，记住训练数据而非学习规律。

###### **欠拟合**
训练和验证误差都高，模型过于简单，无法捕捉数据中的模式。

##### **解决过拟合**
###### **正则化技术**
L1/L2 正则化，Dropout，提前停止等 (见前文)。

###### **数据增强**
扩大训练集，增加样本多样性。

###### **简化模型**
减少层数或神经元数量。

##### **解决欠拟合**
###### **增加模型复杂度**
更深/更宽的网络，更强大的模型族。

###### **减少正则化强度**
降低约束，增加模型灵活性。

###### **特征工程**
创建更有信息量的输入特征。

#### **训练不稳定**
##### **原因**
###### **学习率不当**
过大导致发散，过小导致收敛缓慢。

###### **梯度噪声**
随机梯度下降的固有随机性。

###### **病态损失曲面**
存在鞍点、狭窄峡谷等不利于优化的地形特征。

##### **解决方案**
###### **学习率调度**
动态调整学习率，如余弦退火、降低调度等。

###### **高级优化器**
使用动量、自适应学习率等方法 (Adam, RMSProp)。

###### **梯度累积**
多批次累积梯度后更新，减少噪声。

###### **批量大小选择**
较大的批量通常带来更稳定的梯度估计，但可能影响泛化。

### 4. 部署与优化
#### **模型压缩**
##### **知识蒸馏 (Knowledge Distillation)**
###### **原理**
用大模型 (教师) 指导小模型 (学生) 学习，传递"暗知识"，不仅学习硬标签，还学习软标签 (概率分布)。

###### **损失函数**
$$\mathcal{L} = \alpha \mathcal{L}_{CE}(y, \hat{y}_S) + (1-\alpha) \mathcal{L}_{KL}(\hat{y}_T/\tau, \hat{y}_S/\tau)$$
其中 $\tau$ 是温度系数，控制软标签的平滑程度。

##### **模型剪枝 (Pruning)**
###### **原理**
去除对最终预测贡献小的连接或神经元，减少参数量和计算量。

###### **策略**
**结构化剪枝**: 移除整个神经元/通道，便于加速。
**非结构化剪枝**: 移除单个权重，产生稀疏矩阵。

##### **量化 (Quantization)**
###### **原理**
将浮点权重转换为低精度表示 (如从32位浮点数到8位整数)，减少内存使用和加速推理。

###### **技术**
**训练后量化**: 在预训练模型上直接应用。
**量化感知训练**: 在训练过程中模拟量化效果。

##### **模型裁剪 (Pruning)**
###### **结构化裁剪**
整体移除部分卷积核、注意力头或完整层。

###### **非结构化裁剪**
移除网络中不重要的单个权重或连接。

#### **部署考虑**
##### **硬件适配**
###### **GPU 优化**
针对 CUDA 编程，利用张量核心等特殊硬件。

###### **移动设备优化**
针对 ARM 架构，优化内存使用和能耗。

###### **专用加速器**
针对 TPU, NPU 等 AI 专用硬件优化。

##### **批处理优化**
###### **批量推理**
增大批次提高吞吐量，适合非实时场景。

###### **动态批处理**
实时调整批大小，平衡延迟和吞吐量。

##### **服务架构**
###### **模型服务器**
如 TensorFlow Serving, TorchServe, Triton Inference Server。

###### **推理缓存**
缓存常见输入的结果，减少计算。

#### **运行时优化**
##### **图优化**
###### **操作融合**
合并相邻算子，减少内存访问。

###### **计算图优化**
消除冗余操作，优化计算顺序。

##### **内存优化**
###### **梯度检查点 (Gradient Checkpointing)**
在推理时重新计算部分中间结果，而非存储所有激活值，减少内存使用。

###### **精确激活重计算**
仅保存关键节点，其他节点需要时重算。

## 六、前沿方向与技术趋势

### 1. 大型语言模型 (LLM, Large Language Models)
#### **发展历程**
##### **规模扩展**
从 BERT (3.4亿参数) 到 GPT-4 (数万亿参数)，模型规模呈指数增长。

##### **架构演变**
从双向编码器到自回归解码器，再到编码器-解码器结合的混合模型。

#### **关键技术**
##### **预训练-微调范式**
###### **自监督预训练**
通过大规模文本预测任务学习通用语言表示。

###### **指令微调**
针对特定任务指令的监督微调。

###### **RLHF (人类反馈强化学习)**
通过人类偏好数据进一步优化模型输出，使其更有用、无害且诚实。

##### **提示工程 (Prompt Engineering)**
###### **概念**
设计输入提示以引导 LLM 生成有用输出的技术。

###### **技术**
**零样本推理 (Zero-shot)**: 直接使用任务指令。
**少样本推理 (Few-shot)**: 提供任务示例。
**思维链 (Chain of Thought)**: 引导模型一步步推理。

##### **上下文学习 (In-context Learning)**
###### **概念**
模型在推理时通过提示中的示例快速适应新任务，无需参数更新。

###### **机制**
在长度有限的上下文窗口中，模型临时性地"学会"任务模式。

#### **关键挑战**
##### **效率与可访问性**
###### **计算成本**
训练和推理的巨大资源需求。

###### **延迟和吞吐量**
实时交互中的响应速度挑战。

##### **能力边界**
###### **推理局限**
复杂数学、长期规划和逻辑一致性仍存在问题。

###### **长上下文理解**
处理长文档和保持一致性的能力有限。

##### **安全与对齐**
###### **有害内容**
防止生成有害、虚假或误导性内容。

###### **人类价值观对齐**
确保模型行为符合人类意图和价值观。

#### **未来方向**
##### **多模态整合**
跨视觉、语言和音频的统一模型。

##### **工具使用和代理**
LLM 作为控制器，与外部工具和环境交互。

### 2. 神经架构搜索 (NAS, Neural Architecture Search)
#### **核心思想**
自动化深度学习模型的架构设计过程，替代人工试错设计。

#### **主要方法**
##### **基于强化学习的 NAS**
###### **原理**
将架构设计视为序列决策过程，使用 RL 代理探索架构空间并根据性能给予奖励。

###### **代表工作**
Google AutoML 系列，最早的 NAS 方法。

##### **基于进化算法的 NAS**
###### **原理**
使用遗传算法在架构空间中进行搜索，通过交叉和变异产生新架构。

###### **优势**
并行化程度高，可利用群体多样性避免局部最优。

##### **基于梯度的 NAS (Differentiable Architecture Search)**
###### **代表**
DARTS (Differentiable Architecture Search)，通过松弛近似使架构可微。

###### **优势**
显著降低搜索成本，从天级/月级降至小时级。

#### **搜索空间**
##### **基于单元的搜索空间**
搜索重复使用的基本构建单元。

##### **基于层的搜索空间**
逐层设计网络结构。

##### **混合粒度搜索空间**
同时考虑宏观和微观结构设计。

#### **搜索策略**
##### **One-Shot 方法**
训练超网络，共享不同子网络的权重，大幅提高搜索效率。

##### **渐进式搜索**
从简单架构开始，逐步增加复杂度。

#### **挑战与进展**
##### **计算效率**
###### **问题**
早期 NAS 方法计算成本极高 (数千 GPU 天)。

###### **进展**
权重共享、提前停止、代理评估器等大幅降低搜索成本。

##### **多目标优化**
###### **权衡**
同时考虑准确率、延迟、内存使用等多种目标。

###### **方法**
帕累托前沿探索，满足不同应用需求。

### 3. 自监督学习 (Self-supervised Learning)
#### **核心思想**
利用数据内在结构创建监督信号，无需人工标注，从大量未标注数据中学习有用表示。

#### **主要范式**
##### **掩码预测 (Masked Prediction)**
###### **原理**
遮蔽输入的部分内容，训练模型预测被遮蔽部分。

###### **代表**
**NLP**: BERT (Masked Language Modeling)
**视觉**: MAE (Masked Autoencoders), BEiT
**音频**: wav2vec 2.0

##### **对比学习 (Contrastive Learning)**
###### **原理**
学习将语义相似的样本映射到相近的表示空间，将不同样本映射到远离的表示空间。

###### **代表**
**计算机视觉**: SimCLR, MoCo, CLIP (跨模态对比)
**NLP**: SimCSE
**多模态**: CLIP, ALIGN

##### **生成式预测 (Generative Prediction)**
###### **原理**
学习预测或生成输入的一部分或未来部分。

###### **代表**
**GPT 系列**: 预测下一个词
**扩散模型**: 从噪声中恢复原始数据
**视频预测**: 预测未来帧

#### **技术亮点**
##### **数据增强**
###### **定义**
对同一数据创建不同视角，保持语义不变而改变表面特征。

###### **常见技术**
**视觉**: 裁剪、翻转、色彩抖动、模糊等
**文本**: 回译、同义词替换、随机删除等
**音频**: 时间扭曲、加噪、频谱增强等

##### **负样本挖掘**
###### **目的**
在对比学习中找到有挑战性但不太困难的负样本。

###### **方法**
**困难负样本挖掘**: 主动寻找容易混淆的样本
**动量更新的字典**: 维护表示队列，扩大负样本范围

##### **表示校准**
###### **挑战**
表示分布可能退化为不均匀或坍缩表示。

###### **解决方案**
聚类约束、熵最大化、预测归一化等技术。

#### **影响和应用**
##### **预训练基础**
为下游任务提供强大的初始化表示，减少监督数据需求。

##### **泛化能力**
学习更通用的特征，非特定任务导向，提高在新任务和领域的迁移性。

### 4. 可解释 AI (XAI, Explainable AI)
#### **背景与重要性**
##### **黑盒问题**
深度学习模型通常难以解释其决策过程。

##### **信任与采纳**
对高风险应用 (医疗、金融、司法) 尤其需要透明度。

##### **监管要求**
欧盟 AI 法案、GDPR 等日益要求算法解释能力。

#### **主要方法**
##### **事后解释 (Post-hoc Explanation)**
###### **特征归因方法**
**梯度方法**: Grad-CAM, Integrated Gradients, SmoothGrad
**基于扰动**: LIME, SHAP
**反卷积方法**: 反卷积网络, 引导反向传播

###### **可视化技术**
**激活最大化**: 生成最大激活特定神经元的输入
**t-SNE/UMAP**: 高维表示的低维可视化
**注意力图**: 可视化模型关注的输入区域

##### **本质可解释性 (Intrinsic Interpretability)**
###### **可解释架构**
**决策树/森林**: 天然可解释的模型结构
**注意力机制**: 明确表示输入重要性
**基于原型的网络**: 通过相似度比较做决策

###### **概念提取**
**TCAV (Testing with Concept Activation Vectors)**: 测试模型对高级人类概念的敏感性
**概念瓶颈模型**: 强制模型通过可解释概念进行预测

#### **评估解释的标准**
##### **忠实度 (Fidelity)**
解释准确反映模型实际决策过程的程度。

##### **理解性 (Comprehensibility)**
人类理解解释的容易程度。

##### **稳定性 (Stability)**
类似输入产生类似解释的程度。

#### **挑战与研究方向**
##### **评估标准统一**
缺乏评估解释质量的统一标准。

##### **解释与性能权衡**
增加可解释性通常以牺牲性能为代价。

##### **因果解释**
超越相关性，提供因果性解释。

### 5. AI 安全与鲁棒性
#### **对抗性攻击 (Adversarial Attacks)**
##### **原理**
向输入添加精心设计的微小扰动，导致模型产生错误预测。

##### **攻击类型**
###### **白盒攻击**
攻击者完全了解模型架构和参数。
代表方法: FGSM, PGD, C&W

###### **黑盒攻击**
攻击者只能通过输入输出交互了解模型。
代表方法: 迁移攻击, 查询攻击

##### **防御策略**
###### **对抗性训练**
在训练过程中加入对抗样本，增强鲁棒性。

###### **输入净化**
预处理输入以消除潜在扰动。

###### **检测机制**
识别并拒绝处理可能的对抗样本。

#### **数据隐私与安全**
##### **隐私问题**
###### **模型逆向**
从模型中提取训练数据。

###### **成员推断**
确定特定样本是否用于训练模型。

##### **隐私保护方法**
###### **差分隐私 (Differential Privacy)**
向训练过程添加噪声，限制单个样本对模型的影响。

###### **联邦学习 (Federated Learning)**
数据留在本地设备，只共享模型更新。

###### **安全多方计算 (Secure Multi-party Computation)**
允许多方在不共享原始数据的前提下进行联合计算。

#### **AI 安全问题**
##### **训练阶段攻击**
###### **数据中毒 (Data Poisoning)**
向训练数据插入恶意样本，破坏模型行为。

###### **后门攻击 (Backdoor Attacks)**
植入触发器，使模型在特定输入上表现异常。

##### **推理阶段攻击**
###### **模型窃取 (Model Stealing)**
通过查询重建专有模型。

###### **模型反转 (Model Inversion)**
从输出重构敏感输入信息。

#### **验证与认证**
##### **形式化验证**
###### **目标**
证明模型在所有可能输入上满足特定安全属性。

###### **挑战**
深度学习的非线性和高维特性使验证复杂化。

##### **认证方法**
###### **输入范围验证**
证明在定义的输入范围内行为可预测。

###### **不变性保证**
确保特定变换下的输出不变。

### 6. 多模态学习
#### **基本概念**
##### **模态定义**
不同类型的信息源或感知通道，如视觉、语言、声音等。

##### **挑战**
###### **表示异质性**
不同模态的数据结构和统计特性差异大。

###### **对齐问题**
确定不同模态间的语义对应关系。

#### **基本任务**
##### **跨模态映射**
###### **文本到图像生成**
如 DALL-E, Midjourney, Stable Diffusion

###### **图像到文本描述**
图像标注、视觉问答

##### **多模态融合**
###### **早期融合 (Early Fusion)**
在特征提取前合并原始输入。

###### **中间融合 (Mid Fusion)**
学习模态间的交互特征。

###### **晚期融合 (Late Fusion)**
各模态独立处理后合并结果。

##### **跨模态检索**
###### **原理**
在统一的表示空间搜索不同模态的相关内容。

###### **代表工作**
CLIP, ALIGN, Florence

#### **技术发展**
##### **统一架构**
###### **编码器-解码器模型**
如 ImageBind、FLAVA 等，使用共享骨干网络处理多种模态。

###### **转换器架构**
将不同模态视为不同"语言"，利用自注意力机制整合。

##### **预训练策略**
###### **联合预训练**
同时在多个模态上预训练模型。

###### **对比预训练**
学习将语义相关的多模态样本映射到相近的特征空间。

#### **前沿应用**
##### **多模态大模型**
###### **代表**
GPT-4, Claude, Gemini 等支持图像和文本的大语言模型。

###### **能力**
理解图像内容、回答视觉问题、生成多模态内容。

##### **多感知互动系统**
###### **虚拟助手**
理解视觉、文本、语音多种输入的智能助手。

###### **机器人操作**
结合视觉和语言指令的机器人控制系统。
