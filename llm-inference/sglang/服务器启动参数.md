



- dtype：模型使用的数据类型，默认为 bfloat16。


["auto", "half", "float16", "bfloat16", "float", "float32"]

"Data type for model weights and activations.\n\n"
'* "auto" will use FP16 precision for FP32 and FP16 models, and '
"BF16 precision for BF16 models.\n"
'* "half" for FP16. Recommended for AWQ quantization.\n'
'* "float16" is the same as "half".\n'
'* "bfloat16" for a balance between precision and range.\n'
'* "float" is shorthand for FP32 precision.\n'
'* "float32" for FP32 precision.


参考：_get_and_verify_dtype


- kv_cache_dtype: kv 缓存的数据类型，默认为 dtype。

["auto", "fp8_e5m2", "fp8_e4m3"],

'Data type for kv cache storage. "auto" will use model data type. "fp8_e5m2" and "fp8_e4m3" is supported for CUDA 11.8+.',



fp8_e4m3 需要提供 quantization_param_path， 默认 scaling factors 为 1.0，会影响精度。


- schedule_policy




